{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 21:54:44.806261: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-07 21:54:47.552775: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-07 21:54:47.552925: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-07 21:54:47.552934: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close Volume</th>\n",
       "      <th>Time</th>\n",
       "      <th>Quote asset volume</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>Taker buy base asset volume</th>\n",
       "      <th>Taker buy quote asset volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188312</th>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>57517.42</td>\n",
       "      <td>57526.28</td>\n",
       "      <td>57485.00</td>\n",
       "      <td>57485.07</td>\n",
       "      <td>42.575735</td>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>2.448258e+06</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>15.319691</td>\n",
       "      <td>880913.090845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188313</th>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>57485.07</td>\n",
       "      <td>57496.42</td>\n",
       "      <td>57466.75</td>\n",
       "      <td>57481.49</td>\n",
       "      <td>34.205467</td>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>1.966194e+06</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>15.971891</td>\n",
       "      <td>918058.816162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188314</th>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>57477.18</td>\n",
       "      <td>57509.99</td>\n",
       "      <td>57458.18</td>\n",
       "      <td>57470.00</td>\n",
       "      <td>30.211789</td>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>1.736514e+06</td>\n",
       "      <td>955.0</td>\n",
       "      <td>13.054229</td>\n",
       "      <td>750364.577319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188315</th>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>57470.00</td>\n",
       "      <td>57470.01</td>\n",
       "      <td>57400.00</td>\n",
       "      <td>57450.90</td>\n",
       "      <td>45.354728</td>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>2.605080e+06</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>12.615628</td>\n",
       "      <td>724559.233035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188316</th>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>57450.89</td>\n",
       "      <td>57475.66</td>\n",
       "      <td>57435.51</td>\n",
       "      <td>57450.19</td>\n",
       "      <td>14.168318</td>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>8.140594e+05</td>\n",
       "      <td>730.0</td>\n",
       "      <td>7.247751</td>\n",
       "      <td>416412.022206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open Time      Open      High       Low     Close  Close Volume  \\\n",
       "188312  1.620794e+12  57517.42  57526.28  57485.00  57485.07     42.575735   \n",
       "188313  1.620794e+12  57485.07  57496.42  57466.75  57481.49     34.205467   \n",
       "188314  1.620794e+12  57477.18  57509.99  57458.18  57470.00     30.211789   \n",
       "188315  1.620794e+12  57470.00  57470.01  57400.00  57450.90     45.354728   \n",
       "188316  1.620794e+12  57450.89  57475.66  57435.51  57450.19     14.168318   \n",
       "\n",
       "                Time  Quote asset volume  Number of trades  \\\n",
       "188312  1.620794e+12        2.448258e+06            1195.0   \n",
       "188313  1.620794e+12        1.966194e+06            1096.0   \n",
       "188314  1.620794e+12        1.736514e+06             955.0   \n",
       "188315  1.620794e+12        2.605080e+06            1559.0   \n",
       "188316  1.620794e+12        8.140594e+05             730.0   \n",
       "\n",
       "        Taker buy base asset volume  Taker buy quote asset volume  \n",
       "188312                    15.319691                 880913.090845  \n",
       "188313                    15.971891                 918058.816162  \n",
       "188314                    13.054229                 750364.577319  \n",
       "188315                    12.615628                 724559.233035  \n",
       "188316                     7.247751                 416412.022206  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import csv  # for reading and writing CSV files\n",
    "import matplotlib.pyplot as plt  # for creating plots and charts\n",
    "import numpy as np  # for numerical computing with Python\n",
    "import pandas as pd  # for data manipulation and analysis\n",
    "import pathlib  # for interacting with file paths in a cross-platform manner\n",
    "import tensorflow as tf  # for machine learning and deep learning\n",
    "from keras.layers import Dense, Activation  # for building deep learning models in TensorFlow\n",
    "from keras.models import Sequential  # for building deep learning models in TensorFlow\n",
    "from keras.optimizers import Adam, RMSprop  # for building deep learning models in TensorFlow\n",
    "from keras.callbacks import History\n",
    "from sklearn.model_selection import train_test_split  # for model selection and evaluation\n",
    "from sklearn.preprocessing import MinMaxScaler  # for preprocessing data\n",
    "from tensorflow import keras  # for building deep learning models in TensorFlow\n",
    "from tensorflow.keras import layers  # for building deep learning models in TensorFlow\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(tf.__version__)\n",
    "\n",
    "# Define column names for the CSV file\n",
    "column_names = ['Open Time','Open','High','Low','Close',\n",
    "                'Close Volume', 'Time', 'Quote asset volume',\n",
    "               'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume']\n",
    "               \n",
    "\n",
    "# Read in the CSV file using pandas\n",
    "raw_dataset = pd.read_csv(\"main.csv\", names=column_names,\n",
    "                      na_values = \"?\", comment='\\t', dtype='float',\n",
    "                      sep=\",\", skipinitialspace=True)\n",
    "\n",
    "# Copy the data from the raw dataset to a new dataframe\n",
    "dataset = raw_dataset.copy()\n",
    "\n",
    "# Print the last few rows of the dataset\n",
    "dataset.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.pop(\"Open Time\")\n",
    "dataset.pop(\"Time\")\n",
    "# Randomly select 80% of the rows from the dataset and store them in a new dataframe\n",
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "\n",
    "# Remove the rows in the training dataset from the original dataset, leaving the remaining rows in a new dataframe\n",
    "test_dataset = dataset.drop(train_dataset.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistical summary of the training dataset\n",
    "train_stats = train_dataset.describe()\n",
    "\n",
    "# Remove the \"Close\" column from the statistical summary\n",
    "train_stats.pop(\"Close\")\n",
    "\n",
    "# Transpose the statistical summary so that it's in a more useful shape\n",
    "train_stats = train_stats.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"Close\" column from the training dataset and store it in a new dataframe\n",
    "train_labels = train_dataset.pop('Close')\n",
    "\n",
    "# Remove the \"Close\" column from the testing dataset and store it in a new dataframe\n",
    "test_labels = test_dataset.pop('Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(train_dataset)\n",
    "normed_train_dataset = scaler.transform(train_dataset)\n",
    "normed_test_dataset = scaler.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150654, 8)\n",
      "(150654,)\n"
     ]
    }
   ],
   "source": [
    "print(normed_train_dataset.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54176     38273.80\n",
      "22054     36653.35\n",
      "25894     36570.67\n",
      "3604      34482.99\n",
      "96019     50880.06\n",
      "            ...   \n",
      "58124     46408.25\n",
      "114876    57751.49\n",
      "89163     51009.62\n",
      "155465    56929.00\n",
      "90475     48084.80\n",
      "Name: Close, Length: 150654, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============== Parte Manual ===============#\n",
    "neuronios = 32\n",
    "act_h = \"relu\"\n",
    "act_out = \"relu\"\n",
    "learnr = 0.001\n",
    "camadas = 1\n",
    "epochs_n = 30\n",
    "\n",
    "# Set up neural network model\n",
    "\"\"\"\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(neuronios, activation=act_h, input_shape=[8]),\n",
    "    layers.Dense(neuronios, activation=act_h),\n",
    "    layers.Dense(neuronios, activation=act_h),\n",
    "    layers.Dense(neuronios, activation=act_h),\n",
    "    #layers.Dense(neuronios, activation=act_h),\n",
    "    #layers.Dense(neuronios, activation=act_h),\n",
    "    layers.Dense(1,activation=act_out)\n",
    "  ])\n",
    "\"\"\"\n",
    "\n",
    "# Set up model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=(8, 1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learnr)\n",
    "\n",
    "model.compile(loss='mse',optimizer=optimizer,metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 6, 32)             128       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 3, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 97        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 225\n",
      "Trainable params: 225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 121ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00070898],\n",
       "       [0.00113801],\n",
       "       [0.        ],\n",
       "       [0.00382435],\n",
       "       [0.        ],\n",
       "       [0.00504166],\n",
       "       [0.        ],\n",
       "       [0.00436885]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = normed_train_dataset[:8]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "30131/30131 - 106s - loss: 696409792.0000 - mae: 18250.3242 - mse: 696409792.0000 - 106s/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "30131/30131 - 100s - loss: 1434374.7500 - mae: 667.2150 - mse: 1434374.7500 - 100s/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "30131/30131 - 94s - loss: 918578.2500 - mae: 527.1177 - mse: 918578.2500 - 94s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "30131/30131 - 95s - loss: 551395.8125 - mae: 402.2287 - mse: 551395.8125 - 95s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "30131/30131 - 102s - loss: 307267.8750 - mae: 289.8564 - mse: 307267.8750 - 102s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "30131/30131 - 116s - loss: 149282.9844 - mae: 187.1277 - mse: 149282.9844 - 116s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "30131/30131 - 103s - loss: 62852.9062 - mae: 102.4128 - mse: 62852.9062 - 103s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "30131/30131 - 103s - loss: 27288.9648 - mae: 54.6871 - mse: 27288.9648 - 103s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "30131/30131 - 104s - loss: 18808.6367 - mae: 47.4876 - mse: 18808.6367 - 104s/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "30131/30131 - 110s - loss: 15986.8105 - mae: 47.6979 - mse: 15986.8105 - 110s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "30131/30131 - 116s - loss: 14160.2568 - mae: 47.3983 - mse: 14160.2568 - 116s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "30131/30131 - 117s - loss: 12655.5771 - mae: 45.9305 - mse: 12655.5771 - 117s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "30131/30131 - 119s - loss: 11293.7969 - mae: 45.1146 - mse: 11293.7969 - 119s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "30131/30131 - 112s - loss: 10230.5742 - mae: 44.5747 - mse: 10230.5742 - 112s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "30131/30131 - 118s - loss: 9276.8213 - mae: 43.6434 - mse: 9276.8213 - 118s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "30131/30131 - 120s - loss: 8473.0977 - mae: 43.0394 - mse: 8473.0977 - 120s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "30131/30131 - 118s - loss: 7807.2368 - mae: 42.5355 - mse: 7807.2368 - 118s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "30131/30131 - 120s - loss: 7312.3623 - mae: 42.2143 - mse: 7312.3623 - 120s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "30131/30131 - 120s - loss: 6939.4941 - mae: 41.6893 - mse: 6939.4941 - 120s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "30131/30131 - 122s - loss: 6608.7402 - mae: 41.1230 - mse: 6608.7402 - 122s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "30131/30131 - 110s - loss: 6352.9644 - mae: 40.8500 - mse: 6352.9644 - 110s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "30131/30131 - 108s - loss: 5951.8423 - mae: 39.2637 - mse: 5951.8423 - 108s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "30131/30131 - 110s - loss: 5436.1562 - mae: 36.3945 - mse: 5436.1562 - 110s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "30131/30131 - 110s - loss: 5202.5703 - mae: 35.5781 - mse: 5202.5703 - 110s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "30131/30131 - 109s - loss: 4988.5015 - mae: 35.0687 - mse: 4988.5015 - 109s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "30131/30131 - 111s - loss: 4785.2490 - mae: 34.4508 - mse: 4785.2490 - 111s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "30131/30131 - 111s - loss: 4586.4434 - mae: 33.9955 - mse: 4586.4438 - 111s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "30131/30131 - 108s - loss: 4399.1436 - mae: 33.6271 - mse: 4399.1436 - 108s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "30131/30131 - 104s - loss: 4223.2988 - mae: 33.0113 - mse: 4223.2988 - 104s/epoch - 3ms/step\n",
      "Epoch 30/30\n",
      "30131/30131 - 106s - loss: 4056.5471 - mae: 32.5948 - mse: 4056.5471 - 106s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc9302a9ab0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up callbacks\n",
    "history = History()\n",
    "\n",
    "# Train model\n",
    "model.fit(normed_train_dataset, train_labels, verbose=2, batch_size=5, epochs= epochs_n, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177/1177 [==============================] - 4s 3ms/step - loss: 4505.3271 - mae: 32.8007 - mse: 4505.3271\n",
      "Resultado [4505.3271484375, 32.80067825317383, 4505.3271484375]\n",
      "Average loss: 23334678.9888265\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "results = model.evaluate(normed_test_dataset, test_labels)\n",
    "print(\"Resultado\",results)\n",
    "\n",
    "# Print average loss over all epochs\n",
    "print(\"Average loss:\", np.mean(history.history['mse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177/1177 [==============================] - 3s 3ms/step\n",
      "[[28987.543]\n",
      " [28857.324]\n",
      " [28751.812]\n",
      " ...\n",
      " [57846.402]\n",
      " [57699.83 ]\n",
      " [57491.797]]\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "y_pred = model.predict(normed_test_dataset)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelmanualcnn_c4_n32_actnrelu_actosigmoid_lr0.001_lossmae_ep30/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelmanualcnn_c4_n32_actnrelu_actosigmoid_lr0.001_lossmae_ep30/assets\n"
     ]
    }
   ],
   "source": [
    "filename = 'modelmanualcnn_c'+ str(camadas) +'_n'+ str(neuronios) +'_actn'+str(act_h) +'_acto'+str(act_out) +'_lr' + str(learnr) + '_lossmae' +'_ep' + str(epochs_n)\n",
    "model.save(filename, save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
