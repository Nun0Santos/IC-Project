{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n",
      "2023-01-05 06:19:32.169698: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 06:19:39.740463: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-05 06:19:39.740618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-05 06:19:39.740628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Close Volume</th>\n",
       "      <th>Time</th>\n",
       "      <th>Quote asset volume</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>Taker buy base asset volume</th>\n",
       "      <th>Taker buy quote asset volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188312</th>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>57517.42</td>\n",
       "      <td>57526.28</td>\n",
       "      <td>57485.00</td>\n",
       "      <td>57485.07</td>\n",
       "      <td>42.575735</td>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>2.448258e+06</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>15.319691</td>\n",
       "      <td>880913.090845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188313</th>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>57485.07</td>\n",
       "      <td>57496.42</td>\n",
       "      <td>57466.75</td>\n",
       "      <td>57481.49</td>\n",
       "      <td>34.205467</td>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>1.966194e+06</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>15.971891</td>\n",
       "      <td>918058.816162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188314</th>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>57477.18</td>\n",
       "      <td>57509.99</td>\n",
       "      <td>57458.18</td>\n",
       "      <td>57470.00</td>\n",
       "      <td>30.211789</td>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>1.736514e+06</td>\n",
       "      <td>955.0</td>\n",
       "      <td>13.054229</td>\n",
       "      <td>750364.577319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188315</th>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>57470.00</td>\n",
       "      <td>57470.01</td>\n",
       "      <td>57400.00</td>\n",
       "      <td>57450.90</td>\n",
       "      <td>45.354728</td>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>2.605080e+06</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>12.615628</td>\n",
       "      <td>724559.233035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188316</th>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>57450.89</td>\n",
       "      <td>57475.66</td>\n",
       "      <td>57435.51</td>\n",
       "      <td>57450.19</td>\n",
       "      <td>14.168318</td>\n",
       "      <td>1.620794e+12</td>\n",
       "      <td>8.140594e+05</td>\n",
       "      <td>730.0</td>\n",
       "      <td>7.247751</td>\n",
       "      <td>416412.022206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open Time      Open      High       Low     Close  Close Volume  \\\n",
       "188312  1.620794e+12  57517.42  57526.28  57485.00  57485.07     42.575735   \n",
       "188313  1.620794e+12  57485.07  57496.42  57466.75  57481.49     34.205467   \n",
       "188314  1.620794e+12  57477.18  57509.99  57458.18  57470.00     30.211789   \n",
       "188315  1.620794e+12  57470.00  57470.01  57400.00  57450.90     45.354728   \n",
       "188316  1.620794e+12  57450.89  57475.66  57435.51  57450.19     14.168318   \n",
       "\n",
       "                Time  Quote asset volume  Number of trades  \\\n",
       "188312  1.620794e+12        2.448258e+06            1195.0   \n",
       "188313  1.620794e+12        1.966194e+06            1096.0   \n",
       "188314  1.620794e+12        1.736514e+06             955.0   \n",
       "188315  1.620794e+12        2.605080e+06            1559.0   \n",
       "188316  1.620794e+12        8.140594e+05             730.0   \n",
       "\n",
       "        Taker buy base asset volume  Taker buy quote asset volume  \n",
       "188312                    15.319691                 880913.090845  \n",
       "188313                    15.971891                 918058.816162  \n",
       "188314                    13.054229                 750364.577319  \n",
       "188315                    12.615628                 724559.233035  \n",
       "188316                     7.247751                 416412.022206  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries and modules\n",
    "import csv  # for reading and writing CSV files\n",
    "import matplotlib.pyplot as plt  # for creating plots and charts\n",
    "import numpy as np  # for numerical computing with Python\n",
    "import pandas as pd  # for data manipulation and analysis\n",
    "import pathlib  # for interacting with file paths in a cross-platform manner\n",
    "import seaborn as sns  # for statistical data visualization\n",
    "import tensorflow as tf  # for machine learning and deep learning\n",
    "from keras.layers import Dense, Activation  # for building deep learning models in TensorFlow\n",
    "from keras.models import Sequential  # for building deep learning models in TensorFlow\n",
    "from keras.optimizers import Adam, RMSprop  # for building deep learning models in TensorFlow\n",
    "from keras.callbacks import History\n",
    "from sklearn.model_selection import train_test_split  # for model selection and evaluation\n",
    "from sklearn.preprocessing import MinMaxScaler  # for preprocessing data\n",
    "from tensorflow import keras  # for building deep learning models in TensorFlow\n",
    "from tensorflow.keras import layers  # for building deep learning models in TensorFlow\n",
    "\n",
    "\n",
    "# Print TensorFlow version\n",
    "print(tf.__version__)\n",
    "\n",
    "# Define column names for the CSV file\n",
    "column_names = ['Open Time','Open','High','Low','Close',\n",
    "                'Close Volume', 'Time', 'Quote asset volume',\n",
    "               'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume']\n",
    "               \n",
    "\n",
    "# Read in the CSV file using pandas\n",
    "raw_dataset = pd.read_csv(\"main.csv\", names=column_names,\n",
    "                      na_values = \"?\", comment='\\t', dtype='float',\n",
    "                      sep=\",\", skipinitialspace=True)\n",
    "\n",
    "# Copy the data from the raw dataset to a new dataframe\n",
    "dataset = raw_dataset.copy()\n",
    "\n",
    "# Print the last few rows of the dataset\n",
    "dataset.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.pop(\"Open Time\")\n",
    "dataset.pop(\"Time\")\n",
    "# Randomly select 80% of the rows from the dataset and store them in a new dataframe\n",
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "\n",
    "# Remove the rows in the training dataset from the original dataset, leaving the remaining rows in a new dataframe\n",
    "test_dataset = dataset.drop(train_dataset.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistical summary of the training dataset\n",
    "train_stats = train_dataset.describe()\n",
    "\n",
    "# Remove the \"Close\" column from the statistical summary\n",
    "train_stats.pop(\"Close\")\n",
    "\n",
    "# Transpose the statistical summary so that it's in a more useful shape\n",
    "train_stats = train_stats.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"Close\" column from the training dataset and store it in a new dataframe\n",
    "train_labels = train_dataset.pop('Close')\n",
    "\n",
    "# Remove the \"Close\" column from the testing dataset and store it in a new dataframe\n",
    "test_labels = test_dataset.pop('Close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(train_dataset)\n",
    "normed_train_dataset = scaler.transform(train_dataset)\n",
    "normed_test_dataset = scaler.transform(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150654, 8)\n",
      "(150654,)\n"
     ]
    }
   ],
   "source": [
    "print(normed_train_dataset.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54176     38273.80\n",
      "22054     36653.35\n",
      "25894     36570.67\n",
      "3604      34482.99\n",
      "96019     50880.06\n",
      "            ...   \n",
      "58124     46408.25\n",
      "114876    57751.49\n",
      "89163     51009.62\n",
      "155465    56929.00\n",
      "90475     48084.80\n",
      "Name: Close, Length: 150654, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-05 06:19:47.080517: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 06:19:47.892883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 06:19:47.893951: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 06:19:47.896137: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-05 06:19:47.898209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 06:19:47.898977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 06:19:47.899550: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 06:19:48.808746: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 06:19:48.809142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 06:19:48.809441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-05 06:19:48.809604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4546 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "#=============== Parte Manual ===============#\n",
    "neuronios = 32\n",
    "act_h = \"relu\"\n",
    "act_out = \"sigmoid\"\n",
    "learnr = 0.001\n",
    "camadas = 6\n",
    "epochs_n = 30\n",
    "\n",
    "# Set up neural network model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(neuronios, activation=act_h, input_shape=[8]),\n",
    "    layers.Dense(neuronios, activation=act_h),\n",
    "    layers.Dense(neuronios, activation=act_h),\n",
    "    layers.Dense(neuronios, activation=act_h),\n",
    "    layers.Dense(neuronios, activation=act_h),\n",
    "    layers.Dense(neuronios, activation=act_h),\n",
    "    layers.Dense(1,activation=act_h)\n",
    "  ])\n",
    "\n",
    "# Compile model\n",
    "optimizer = Adam(learnr)\n",
    "\n",
    "model.compile(loss='mse',optimizer=optimizer,metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                288       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,601\n",
      "Trainable params: 5,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.02227697],\n",
       "       [0.01879085],\n",
       "       [0.01871964],\n",
       "       [0.01471416],\n",
       "       [0.04778258],\n",
       "       [0.00899234],\n",
       "       [0.04423985],\n",
       "       [0.01642821]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch = normed_train_dataset[:8]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "30131/30131 - 94s - loss: 12291802.0000 - mae: 369.5634 - mse: 12291802.0000 - 94s/epoch - 3ms/step\n",
      "Epoch 2/30\n",
      "30131/30131 - 87s - loss: 7471.4604 - mae: 65.0689 - mse: 7471.4604 - 87s/epoch - 3ms/step\n",
      "Epoch 3/30\n",
      "30131/30131 - 87s - loss: 7502.1836 - mae: 63.4426 - mse: 7502.1836 - 87s/epoch - 3ms/step\n",
      "Epoch 4/30\n",
      "30131/30131 - 85s - loss: 6897.1064 - mae: 61.8129 - mse: 6897.1064 - 85s/epoch - 3ms/step\n",
      "Epoch 5/30\n",
      "30131/30131 - 85s - loss: 6620.8584 - mae: 61.0726 - mse: 6620.8584 - 85s/epoch - 3ms/step\n",
      "Epoch 6/30\n",
      "30131/30131 - 89s - loss: 6599.9839 - mae: 61.0896 - mse: 6599.9839 - 89s/epoch - 3ms/step\n",
      "Epoch 7/30\n",
      "30131/30131 - 85s - loss: 6418.5166 - mae: 60.3757 - mse: 6418.5166 - 85s/epoch - 3ms/step\n",
      "Epoch 8/30\n",
      "30131/30131 - 86s - loss: 6205.6626 - mae: 59.3663 - mse: 6205.6626 - 86s/epoch - 3ms/step\n",
      "Epoch 9/30\n",
      "30131/30131 - 85s - loss: 6203.6113 - mae: 59.2727 - mse: 6203.6113 - 85s/epoch - 3ms/step\n",
      "Epoch 10/30\n",
      "30131/30131 - 88s - loss: 6092.5942 - mae: 58.9167 - mse: 6092.5942 - 88s/epoch - 3ms/step\n",
      "Epoch 11/30\n",
      "30131/30131 - 101s - loss: 6091.6040 - mae: 58.5349 - mse: 6091.6040 - 101s/epoch - 3ms/step\n",
      "Epoch 12/30\n",
      "30131/30131 - 94s - loss: 5832.2744 - mae: 57.4571 - mse: 5832.2744 - 94s/epoch - 3ms/step\n",
      "Epoch 13/30\n",
      "30131/30131 - 84s - loss: 5976.8965 - mae: 57.8950 - mse: 5976.8965 - 84s/epoch - 3ms/step\n",
      "Epoch 14/30\n",
      "30131/30131 - 76s - loss: 5892.2354 - mae: 57.8549 - mse: 5892.2354 - 76s/epoch - 3ms/step\n",
      "Epoch 15/30\n",
      "30131/30131 - 77s - loss: 5704.8286 - mae: 56.7505 - mse: 5704.8286 - 77s/epoch - 3ms/step\n",
      "Epoch 16/30\n",
      "30131/30131 - 81s - loss: 5702.1885 - mae: 56.5718 - mse: 5702.1885 - 81s/epoch - 3ms/step\n",
      "Epoch 17/30\n",
      "30131/30131 - 75s - loss: 5652.5464 - mae: 56.7640 - mse: 5652.5464 - 75s/epoch - 3ms/step\n",
      "Epoch 18/30\n",
      "30131/30131 - 76s - loss: 5656.5513 - mae: 56.5672 - mse: 5656.5513 - 76s/epoch - 3ms/step\n",
      "Epoch 19/30\n",
      "30131/30131 - 74s - loss: 5499.2983 - mae: 55.9287 - mse: 5499.2983 - 74s/epoch - 2ms/step\n",
      "Epoch 20/30\n",
      "30131/30131 - 73s - loss: 5549.9932 - mae: 56.0774 - mse: 5549.9932 - 73s/epoch - 2ms/step\n",
      "Epoch 21/30\n",
      "30131/30131 - 70s - loss: 5432.1177 - mae: 55.4255 - mse: 5432.1177 - 70s/epoch - 2ms/step\n",
      "Epoch 22/30\n",
      "30131/30131 - 70s - loss: 5282.9370 - mae: 54.8563 - mse: 5282.9370 - 70s/epoch - 2ms/step\n",
      "Epoch 23/30\n",
      "30131/30131 - 70s - loss: 5465.4717 - mae: 55.4974 - mse: 5465.4717 - 70s/epoch - 2ms/step\n",
      "Epoch 24/30\n",
      "30131/30131 - 71s - loss: 5261.6333 - mae: 54.6690 - mse: 5261.6333 - 71s/epoch - 2ms/step\n",
      "Epoch 25/30\n",
      "30131/30131 - 70s - loss: 5292.2642 - mae: 54.8394 - mse: 5292.2642 - 70s/epoch - 2ms/step\n",
      "Epoch 26/30\n",
      "30131/30131 - 70s - loss: 5273.3154 - mae: 54.6508 - mse: 5273.3154 - 70s/epoch - 2ms/step\n",
      "Epoch 27/30\n",
      "30131/30131 - 70s - loss: 5249.8921 - mae: 54.5868 - mse: 5249.8921 - 70s/epoch - 2ms/step\n",
      "Epoch 28/30\n",
      "30131/30131 - 71s - loss: 5198.3096 - mae: 54.0556 - mse: 5198.3096 - 71s/epoch - 2ms/step\n",
      "Epoch 29/30\n",
      "30131/30131 - 70s - loss: 5094.6245 - mae: 53.7142 - mse: 5094.6245 - 70s/epoch - 2ms/step\n",
      "Epoch 30/30\n",
      "30131/30131 - 73s - loss: 5131.9150 - mae: 53.8915 - mse: 5131.9150 - 73s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2d0127be0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up callbacks\n",
    "history = History()\n",
    "\n",
    "# Train model\n",
    "model.fit(normed_train_dataset, train_labels, verbose=2, batch_size=5, epochs= epochs_n, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177/1177 [==============================] - 3s 2ms/step - loss: 5943.2900 - mae: 62.2333 - mse: 5943.2900\n",
      "Resultado [5943.2900390625, 62.23331832885742, 5943.2900390625]\n",
      "Average loss: 415401.82915039064\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "results = model.evaluate(normed_test_dataset, test_labels)\n",
    "print(\"Resultado\",results)\n",
    "\n",
    "# Print average loss over all epochs\n",
    "print(\"Average loss:\", np.mean(history.history['mse']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1177/1177 [==============================] - 2s 2ms/step\n",
      "[[28952.555]\n",
      " [28826.035]\n",
      " [28733.871]\n",
      " ...\n",
      " [57781.207]\n",
      " [57633.293]\n",
      " [57425.598]]\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "y_pred = model.predict(normed_test_dataset)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: modelmanual_c6_n32_actnrelu_actosigmoid_lr0.001_lossmae_ep30/assets\n"
     ]
    }
   ],
   "source": [
    "filename = 'modelmanual_c'+ str(camadas) +'_n'+ str(neuronios) +'_actn'+str(act_h) +'_acto'+str(act_out) +'_lr' + str(learnr) + '_lossmae' +'_ep' + str(epochs_n)\n",
    "model.save(filename, save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
