{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "(135587, 8)\n",
      "(135587,)\n",
      "[6.48000000e+04 6.48540000e+04 6.46851700e+04 1.86693905e+03\n",
      " 1.04698422e+08 2.75170000e+04 1.17949386e+03 5.56839455e+07]\n",
      "64800.0\n",
      "[28241.95 28764.23 28130.       0.       0.       0.       0.       0.  ]\n",
      "28235.47\n",
      "(15066, 8)\n",
      "(15066,)\n",
      "[6.45772500e+04 6.45913700e+04 6.45317600e+04 1.44634172e+03\n",
      " 8.06229633e+07 2.91640000e+04 9.29264511e+02 4.65329631e+07]\n",
      "64568.09\n",
      "[28844.48 28844.48 28823.49     0.       0.       0.       0.       0.  ]\n",
      "28839.57\n",
      "(37664, 8)\n",
      "(37664,)\n",
      "[6.46566100e+04 6.46614600e+04 6.45579100e+04 1.57138110e+03\n",
      " 6.43827379e+07 2.58190000e+04 1.04336255e+03 3.87596190e+07]\n",
      "64577.26\n",
      "[28769.77 28816.34 28751.58     0.       0.       0.       0.       0.  ]\n",
      "28759.35\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad() \u001b[39m#reset gráfico do gradiente\u001b[39;00m\n\u001b[1;32m     81\u001b[0m y_pred \u001b[39m=\u001b[39m network(x) \u001b[39m#previsão da rede para este x\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m loss \u001b[39m=\u001b[39m criterion(y,y_pred) \u001b[39m#diferença entre o que devia ter previsto e o que rede preveu \u001b[39;00m\n\u001b[1;32m     83\u001b[0m loss\u001b[39m.\u001b[39mbackward() \u001b[39m#para calcular o gradiente\u001b[39;00m\n\u001b[1;32m     84\u001b[0m optimizer\u001b[39m.\u001b[39mstep() \u001b[39m#atualizar os pesos\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 536\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mmse_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:3291\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3289\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3291\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[1;32m   3292\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     73\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataset import BitcoinRegressionDataset\n",
    "from network import network\n",
    "import csv\n",
    "\n",
    "x ,y = [],[]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "with open(\"Bitcoin Price (USD).csv\") as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=';')\n",
    "    next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        #print(row)\n",
    "        y.append(float(row[4])) #saidas\n",
    "        x.append([float(row[1]),float(row[2]),float(row[3]),float(row[5]),float(row[7]),float(row[8]),float(row[9]),float(row[10])]) #features que queremos (entradas)\n",
    "\n",
    "N = len(y) #Numero total de exemplos\n",
    "\"\"\"\n",
    "train_x = x[:int(N*0.8)] #8 linhas, do 80% do total de colunas\n",
    "print(train_x)\n",
    "train_y = y[:int(N*0.8)]\n",
    "\n",
    "val_x = x[int(N*0.8):int(N*0.9)]\n",
    "val_y = y[int(N*0.8):int(N*0.9)]\n",
    "\n",
    "test_x = x[int(N*0.9):]\n",
    "test_y = y[int(N*0.9):]\n",
    "\n",
    "\"\"\"\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.1, random_state=0)\n",
    "\n",
    "trainset = BitcoinRegressionDataset(train_x,train_y) #matriz com dados normalizados\n",
    "\n",
    "data_loader_train = torch.utils.data.DataLoader( #Otimizar a maneira como le as coisas\n",
    "    trainset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "valset = BitcoinRegressionDataset(val_x,val_y) #matriz com os dados de validacao\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    valset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "testset = BitcoinRegressionDataset(test_x,test_y) #matrix com dados para tete\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "network = network(8,256,256) #Número features , 2 camadas com 256 neuronios\n",
    "\n",
    "network = network.to(device)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=3e-4) #lr = learning rate, parametros para otimizar arede\n",
    "\n",
    "criterion = torch.nn.MSELoss() #função de treino \n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = 0\n",
    "    val_loss = 0\n",
    "    for x,y in data_loader_train:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad() #reset gráfico do gradiente\n",
    "        y_pred = network(x) #previsão da rede para este x\n",
    "        loss = criterion(y,y_pred) #diferença entre o que devia ter previsto e o que rede preveu \n",
    "        loss.backward() #para calcular o gradiente\n",
    "        optimizer.step() #atualizar os pesos\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    for x,y in data_loader_val: \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)      \n",
    "        y_pred = network(x)\n",
    "        loss = criterion(y,y_pred)\n",
    "        \n",
    "\n",
    "        val_loss += loss.item()\n",
    "    \n",
    "    train_loss = train_loss / len(train_y)\n",
    "    val_loss = val_loss / len(val_y)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/100 : Train loss = {train_loss} | Val loss = {val_loss}\")\n",
    "\n",
    "test_loss = 0\n",
    "for x,y in data_loader_test:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)       \n",
    "    y_pred = network(x)\n",
    "    loss = criterion(y,y_pred)\n",
    "\n",
    "    test_loss += loss.item()\n",
    "\n",
    "test_loss = test_loss / len(test_y)\n",
    "\n",
    "print(f\"Test loss = {test_loss}\")\n",
    "        \n",
    "torch.save(network.state_dict(), \"network.tar\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "passar à rede que devolver entre -1 e 1 || network.load_state_dict(\"network.tar\") preço=network()\n",
    "\n",
    "desnomalizar esse valor\n",
    "\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
