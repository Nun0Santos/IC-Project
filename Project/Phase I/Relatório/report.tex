\documentclass[10pt]{article}

\PassOptionsToPackage{hidelinks}{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, calc, xcolor}
\usepackage{alphabeta} 
\usepackage[pdftex]{graphicx}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage[]{bookmark}
\linespread{1.06}
\setlength{\parskip}{8pt plus2pt minus2pt}

\widowpenalty 10000
\clubpenalty 10000

\newcommand{\eat}[1]{}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\usepackage[official]{eurosym}
\usepackage{enumitem}
\setlist{nolistsep,noitemsep}
\usepackage[]{hyperref}
\usepackage{url}
\usepackage{cite}
\usepackage{lipsum}
\usepackage{indentfirst}
\usepackage{tikz}
\usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,fit,positioning,shapes.symbols,chains}
\usepackage{xcolor,colortbl}
\usepackage{array}

\setlength{\parindent}{2em}
\renewcommand*\contentsname{Índice}
\renewcommand\refname{}

\begin{document}

%===========================================================
\begin{titlepage}
\begin{center}

% Top 
\includegraphics[width=0.55\textwidth]{img/logo-isec-transparente.png}~\\[2cm]


% Title
\HRule \\[0.4cm]
{ \LARGE 
  \textbf{Inteligência Computacional}\\[0.4cm]
}
\HRule \\[1.5cm]

% Docente
{ \large
  \textbf{Docente} \\[0.1cm]
  Inês Dominguês \\ Carlos Pereira \\[2.5cm]
}


% Author
{ \large
  \textbf{Alunos} \\[0.1cm]
  Paulo Henrique Figueira Pestana de Gouveia - a2020121705 \\[0.1cm]
  Nuno Alexandre Almeida Santos - a2019110035\\[0.1cm]
}

\vfill



% Bottom
{\large \today}
 
\end{center}
\end{titlepage}


\newpage



%===========================================================
\tableofcontents
\addtocontents{toc}{\protect\thispagestyle{empty}}
\newpage
\setcounter{page}{1}

%===========================================================
%===========================================================
\large
\section{Introdução}\label{sec:intro}
Este trabalho foi realizado no âmbito da Unidade Curricular 
de Inteligência Computacional, tem por objetivo treinar uma rede 
neuronal capaz de estimar o valor da Bitcoin num determinado minuto.

\vspace{4cm}
\section{Descrição do caso de estudo e objetivos do problema}\label{sec:apre-da-org}
O Dataset escolhido foi Bitcoin Price USD, neste conjunto de dados os dados são gerados no intervalo 
de 1 minuto por uma API (Binance API) entre 1 de janeiro de 2021 a 12 de Maio de 2021.
Inclui várias colunas que mostram a mudança real no preço da Bitcoin também mostra o preço Open, High,
Low, Close da Bitcoin em minutos específicos. 
\begin{itemize}
    \item{Features}
    \begin{enumerate}
        \item Preço de abertura num minuto específico (Open Price of particular minute);
        \item Preço alto num minuto específico (High Price of particular minute);
        \item Preço baixo num minuto específico (Low Price of particular minute);
        \item Fechar Preço num minuto específico (Close Price of particular minute);
        \item Volume total num minuto específico (Total volume of particular minute);
        \item Volume de ativos de cotação (Quote asset volume);
        \item Número de negócios para determinado minuto (Number of trades for particular minute);
        \item Volume de ativos base de compra do tomador (Taker buy base asset volume);
        \item Volume de ativos de cotação de compra do tomador (Taker buy quote asset volume).
    \end{enumerate}
\end{itemize}
\begin{itemize}
    \item{Exemplos: 188318}
\end{itemize}   
Como o Horário de abertura (Open Time) e o Horário de fecho (Close Time) são sempre iguais, retirámos essas colunas das features.
\newpage
\section{Descrição da implementação dos algoritmos}\label{sec:Des-da-imp-dos-alg}

Para treinar o nosso modelo optámos por usar o PyTorch que é uma biblioteca Python de aprendizagem máquina de código aberto.
A principal diferença entre PyTorch e TensorFlow é a escolha entre simplicidade e desempenho: o PyTorch é mais fácil de aprender
(especialmente para programadores Python), enquanto o TensorFlow tem uma curva de aprendizagem, mas tem um desempenho melhor e é mais utilizado na comunidade de desenvolvedores.
\vspace{1cm}
\\Os algoritmos de treino(métricas de avaliação) usádos foram: 
\vspace{1cm}
\begin{itemize}
\item MSE (Erro quadrado médio)
\vspace{1cm}
\begin{equation}
  \vspace{1cm}
  MSE : \sum_{i=1}^{D}(x_i-y_i)^2
\end{equation}
\item MAE (Erro absoluto médio)
\vspace{1cm}
\begin{equation}
  \vspace{1cm}
  MAE : \sum_{i=1}^{D}|x_i-y_i|
\end{equation}
\item RMSE (Raíz quadrada do erro médio)
\vspace{1cm}
\begin{equation}
  \vspace{1cm}
  RMSE : \sqrt{\frac{1}{n}\Sigma_{i=1}^{n}{\Big(\frac{d_i -f_i}{\sigma_i}\Big)^2}}
\end{equation}
\item RSQUARED (Coeficiente de determinação)
\vspace{1cm}
\begin{equation}
  \vspace{1cm}
  RSQUARED : 1 - \frac{SS_{res}}{SS_{tot}}
\end{equation}
\newpage
\end{itemize}
Funções de ativação usadas:
\vspace{1cm}
\begin{itemize}
  \item Softmax
  \begin{equation}
  \vspace{1cm}
  Softmax(x) = \frac{\exp(x_i)}{\sum_j(x_j)}
  \end{equation}
  
  \item RReLU
  \begin{equation}
    \vspace{1cm}
    RReLU(x) =
      \begin{cases}
            x, & \mbox{if } x \geq \mbox{0} \\
            ax, & \mbox{caso contrário}
      \end{cases}
  \end{equation}
  \item Sigmoid
  \begin{equation}
    \vspace{1cm}
    Sigmoid(x) =  \sigma(x) = \frac{1}{1+\exp(-x)}
  \end{equation}
\end{itemize}
\vspace{1cm}
Treinámos 4 redes com as diferentes funções de treino para testar qual teria menor erro:  
\vspace{1cm}
\begin{enumerate}
\item Rede MSE
  \begin{itemize}
    \item Nome - network MSE 2Lay 256 Tanh 8 94e 05.tar
    \item Função de Treino - MSE
    \item Função de Ativação - Tanh
    \item Nº de Neurónios - 256
    \item Nº de Camadas - 2
    \item Learning Rate - 3e-4
    \item Erro de teste - 8,94E-05
  \end{itemize}
  \vspace{2cm}
  \item Rede RMSE
  \begin{itemize}
    \item Nome - network RMSE 2Lay 256 Tanh 0 00228.tar
    \item Função de Treino - RMSE
    \item Função de Ativação - Tanh
    \item Nº de Neuronios - 256
    \item Nº de Camadas - 2
    \item Learning Rate - 3e-4
    \item Erro de teste - 0,0028
  \end{itemize}  
  \vspace{2cm}
  \item Rede MAE
  \begin{itemize} 
    \item Nome - network MAE 2Lay 256 Tanh 0 00173 .tar
    \item Função de Treino - MAE
    \item Função de Ativação - Tanh
    \item Nº de Neuronios - 256
    \item Nº de Camadas - 2
    \item Learning Rate - 3e-4
    \item Erro de teste - 0,00173
  \end{itemize}
  \vspace{2cm}
  \item Rede RSQUARED
  \begin{itemize}
    \item Nome - network R2 2Lay 256 Tanh 0 062.tar
    \item Função de Treino - RSquared
    \item Função de Ativação - Tanh
    \item Nº de Neurónios - 256
    \item Nº de Camadas - 2
    \item Learning Rate - 3e-4
    \item Erro de teste - 0,062   
  \end{itemize}
\end{enumerate}
\vspace{1cm}
A melhor rede obtida na primeira fase, alterando apenas as funções de
treino foi a rede network MSE 2Lay 256 Tanh 8 94e 05.tar (Rede MSE) cujo a 
função de treino foi a MSE (Erro  quadrado  médio).

Foram criadas novas 5 redes cujo a função de treino é a função MSE pois foi
a função que obtivemos melhor resultados, nestas novas 3 redes irão variar vários parâmetros
tais como a função de ativação, número de neurónios e número de camadas.

\vspace{1cm}
\begin{enumerate}
  \item Rede MSE (Softmax para função de ativação)
  \begin{itemize}
    \item Nome - network MSE 2Lay 256 Softmax 0 065.tar
    \item Função de Treino - MSE
    \item Função de Ativação - Softmax
    \item Nº de Neurónios - 256
    \item Nº de Camadas - 2
    \item Learning Rate - 3e-4
    \item Erro de teste - 0,065
  \end{itemize}
  \newpage
  \item Rede MSE (RReLU para função de ativação)
  \begin{itemize}
    \item Nome - network MSE 2Lay 256 RReLU 0 065.tar
    \item Função de Treino - MSE
    \item Função de Ativação - RReLU
    \item Nº de Neurónios - 256
    \item Nº de Camadas - 2
    \item Learning Rate - 3e-4
    \item Erro de teste - 0,0019
  \end{itemize}
  \vspace{1cm}
  \item Rede MSE (Sigmoid para função de ativação)
  \begin{itemize}
    \item Nome - network MSE 2Lay 256 RReLU 0 065.tar
    \item Função de Treino - MSE
    \item Função de Ativação - Sigmoid
    \item Nº de Neurónios - 256
    \item Nº de Camadas - 2
    \item Learning Rate - 3e-4
    \item Erro de teste - 0,0019
  \end{itemize}
  \vspace{1cm}
  \item Com uma camada:
    \begin{itemize}
      \item Nome - network MSE 1Lay 256 Tanh 9 04E 05.tar
      \item Função de Treino - MSE
      \item Função de Ativação - Tanh
      \item Nº de neuronios - 256
      \item Nº de camadas - 1
      \item Learning rate - 3e-4
      \item Erro de teste - 9,04E-05
    \end{itemize}  
    \vspace{1cm}
    \item Com 50 neuronios:
    \begin{itemize}
      \item Nome - network MSE 2Lay 50 Tanh 0 062.tar
      \item Função de Treino - MSE
      \item Função de Ativação - Tanh
      \item Nº de neuronios - 50
      \item Nº de camadas - 2
      \item Learning rate - 3e-4
      \item Erro de teste - 0,062
    \end{itemize}
\end{enumerate}
\newpage

\section{Análise de Resultados}\label{sec:ev-da-org}
\subsection{Diferença nas funções de ativação(métricas de avaliação)}

MSE é uma função diferenciável que facilita a execução de 
operações matemáticas em comparação com uma função 
não diferenciável como MAE. 
Portanto, em muitos modelos, o RMSE é usado como métrica 
padrão para calcular a Função de Perda, apesar de ser mais 
difícil de interpretar do que o MAE.

O menor valor de MAE, MSE e RMSE implica em maior precisão 
de um modelo de regressão. No entanto, um valor mais alto de 
RSquared é considerado desejável.

Para comparar a precisão entre diferentes modelos de 
regressão linear, RMSE é uma escolha melhor do que R Squared.

\subsection{Diferença nas funções de ativação}

Como podemos visualizar nos resultados acima, o função Tanh continua
a ter a melhor performance, isto tudo tem haver da maneira como foram
normalizados os dados.

Os nossos dados estão normalizados entre -1 e 1, sendo que a Softmax e a Sigmoid
limitam o output entre 0 e 1, o que não ajuda para a performance.
Para RReLU aplica a função de unidade de revestimento 
retificado com vazamento aleatório, elemento a elemento,
podendo obter melhor resultados se o seu lower e upperbound
foram bem definidos.

\subsection{Diferença nas configurações da rede}

Sendo um modelo linear, precisamos apenas de uma camada para
rede, sendo que o aumento de camadas não afeta a performance da rede
que é o que acontece nos nossos testes.

Enquanto que na dimunuição da quantidade de neurónios podemos ver 
que a nossa performance da rede piora, pois que quantos mais neurónios
para a nossa rede melhor ela será ao custo de um aumento do tempo
de treino.

\vspace{3cm}
\section{Conclusões}\label{sec:an-da-info-fin-da-org}
Podemos concluir que para este caso a melhor métrica de avaliação
é a MSE com a função de ativação adequada para a maneira como foram
normalizados os dados.

Ao testar com valores esta rede dá valores favoráveis, que infelizmente
não podem ser levados para uso de ganhos financeiros no mercado
da criptomoeda devido ao facto que a nossa rede não tem dados
para prever fatores externos que possam causar por exemplo
um crash no mercado.

Combinamos o interesse ao tópico das criptomoedas hoje em dia, 
para aprofundar o nossa compreenção no tópico de criar redes 
neuronais para previsão de valores de um modelo de regressão.


\vspace{1cm}

\section{Referências}\label{sec:sup-inf-utl}
\bibliographystyle{ieeetr}
\bibliography{refs}
\nocite{Binance_2021}

%===========================================================

%===========================================================

\pagebreak
\end{document} 
